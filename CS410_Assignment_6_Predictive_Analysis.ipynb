{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ESBL5JbQ7L-T",
        "zYxTQ67F7OwZ",
        "LCFsMSMxy4-J",
        "JjmL4oLezUdE",
        "MkoByADS65pF",
        "N6ZR8aNC7koz"
      ],
      "authorship_tag": "ABX9TyPDiUh/2/kWG6XDzaSmqyp/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mrj760/Data-Science-Assignments/blob/main/CS410_Assignment_6_Predictive_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Set-up"
      ],
      "metadata": {
        "id": "fbtEY8nry22n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Imports"
      ],
      "metadata": {
        "id": "3Pxm5O4s7LAR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.compose import make_column_transformer as mkxform, make_column_selector as mksel\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "import random"
      ],
      "metadata": {
        "id": "j-yto5za69xn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Drive"
      ],
      "metadata": {
        "id": "ESBL5JbQ7L-T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fbqyr0DyGDk",
        "outputId": "1900034d-3357-4667-f851-ac25eb25f660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.flush_and_unmount()\n",
        "drive.mount(\"/content/drive\")\n",
        "drivepath = Path() / '/content' / 'drive' / 'MyDrive'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Pandas Printing Options"
      ],
      "metadata": {
        "id": "zYxTQ67F7OwZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_columns', None)  \n",
        "pd.set_option('display.max_colwidth', None)\n",
        "pd.set_option(\"expand_frame_repr\", False)"
      ],
      "metadata": {
        "id": "yv1_iW6C7OPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Obtaining the Data"
      ],
      "metadata": {
        "id": "LCFsMSMxy4-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DONK = pd.read_csv(drivepath / 'donkeys.csv')\n",
        "print(DONK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl1hQdbiy7bK",
        "outputId": "82b15c07-d2ae-46cf-da1a-bd228c2bd1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     BCS    Age       Sex  Length  Girth  Height  Weight  WeightAlt\n",
            "0    3.0     <2  stallion      78     90      90      77        NaN\n",
            "1    2.5     <2  stallion      91     97      94     100        NaN\n",
            "2    1.5     <2  stallion      74     93      95      74        NaN\n",
            "3    3.0     <2    female      87    109      96     116        NaN\n",
            "4    2.5     <2    female      79     98      91      91        NaN\n",
            "..   ...    ...       ...     ...    ...     ...     ...        ...\n",
            "539  3.0  10-15  stallion      98    115     101     145        NaN\n",
            "540  3.0  10-15  stallion     102    126     110     183        NaN\n",
            "541  2.5  10-15  stallion     103    118     103     174        NaN\n",
            "542  3.0    2-5  stallion      91    112     100     139        NaN\n",
            "543  3.0   5-10  stallion     104    124     110     189        NaN\n",
            "\n",
            "[544 rows x 8 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Descriptions"
      ],
      "metadata": {
        "id": "JjmL4oLezUdE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "BCS : Body Condition Score: 1 (emaciated), 3 (healthy), 5 (obese)\n",
        "\n",
        "Age : Age in years : (\\<2), (2-5), (5-10), (10-15), (15-20), (\\>20)\n",
        "\n",
        "Sex : Sex categories: stallion, gelding, female \n",
        "\n",
        "Length : Body length (cm) from front leg elbow to back of pelvis \n",
        "\n",
        "Girth : Body circumference (cm), measured just behind front legs\n",
        "\n",
        "Height : Body height (cm) up to point where neck connects to back \n",
        "\n",
        "Weight : Weight (kilogram)\n",
        "\n",
        "WeightAlt : Second weight measurement taken on a small subset of donkeys\n",
        "\n"
      ],
      "metadata": {
        "id": "A9V0mCx-zabx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1 "
      ],
      "metadata": {
        "id": "6koAUs1E0IVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### State the predictive question you would like to answer."
      ],
      "metadata": {
        "id": "uw7rJ8ol0Zbl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a donkey's weight, based on its : Body Condition; Age; Sex; Length; Girth; Height; Weight?"
      ],
      "metadata": {
        "id": "z0CzG1ko0d-w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Identify whether it is a classification or a regression problem and describe the dataset.\n"
      ],
      "metadata": {
        "id": "VL6a123c0b1Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output is numeric so this is a regression problem."
      ],
      "metadata": {
        "id": "jjevrvtl0vED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2 / Task 3"
      ],
      "metadata": {
        "id": "RAJj0NQI0zDZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform at least one quality check. Clean if necessary.\n",
        "\n",
        "Prepare the data for machine learning by transforming it."
      ],
      "metadata": {
        "id": "UZv_Ld_t04bj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "donk = DONK\n",
        "\n",
        "donk = donk.assign(\n",
        "    Weight=donk[['Weight','WeightAlt']].mean(axis=1) # Turn weight into average if there were two measurements\n",
        "    )\n",
        "donk = donk.drop(columns='WeightAlt')\n",
        "\n",
        "categs = mksel(dtype_include=object)\n",
        "nums = mksel(dtype_include=np.number)\n",
        "# print(f\"Ordinal Columns   : {categs(donk)}\")\n",
        "# print(f\"Numerical Columns : {nums(donk)}\")\n",
        "\n",
        "categ_linear_proc = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "num_linear_proc = MinMaxScaler()\n",
        "\n",
        "xform = mkxform((categ_linear_proc, categs),\n",
        "                (num_linear_proc, nums), \n",
        "                remainder=\"passthrough\")\n",
        "\n",
        "categ_linear_proc = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "num_linear_proc = MinMaxScaler()\n",
        "\n",
        "donk = xform.fit_transform(donk)\n",
        "donk = pd.DataFrame(donk, columns=xform.get_feature_names_out())\n",
        "donk = donk.rename(columns=(lambda x: x.replace('minmaxscaler__','').replace('onehotencoder__','')))\n",
        "# print(donk)"
      ],
      "metadata": {
        "id": "69Sc3m6T08k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4"
      ],
      "metadata": {
        "id": "MaTKo7NP6wd7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split into training/testing datasets"
      ],
      "metadata": {
        "id": "NrDN12A96yAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = list(donk.columns)\n",
        "X.remove('Weight')\n",
        "X = donk[X]\n",
        "y = donk['Weight']\n",
        "\n",
        "rand = random.randint(0,69420)\n",
        "print(f'Seed used for train/test split: {rand}')\n",
        "\n",
        "Xtr, Xtest, ytr, ytest = train_test_split(X, y, test_size=.2, random_state=rand)\n",
        "\n",
        "\n",
        "# print(len(Xtr))\n",
        "# print(len(Xtest))\n",
        "# print(Xtr,end='\\n=================\\n\\n')\n",
        "# print(ytr,end='\\n=================\\n\\n')\n",
        "# print(Xtest,end='\\n=================\\n\\n')\n",
        "# print(ytest,end='\\n=================\\n\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3myKKtZk7rTb",
        "outputId": "d5161803-8a22-46c1-ff34-286dfaa71647"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed used for train/test split: 55522\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Train via training set"
      ],
      "metadata": {
        "id": "MkoByADS65pF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "skmodel = LinearRegression().fit(Xtr,ytr)"
      ],
      "metadata": {
        "id": "vq5XjyzD7rsx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluate via test set"
      ],
      "metadata": {
        "id": "N6ZR8aNC7koz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(output, pred): # Mean Absolute Error\n",
        "    return np.mean(abs(output-pred))\n",
        "\n",
        "def mse(output, pred): # Mean Squared Error\n",
        "    return np.mean((output-pred)**2)\n",
        "\n",
        "skpred = skmodel.predict(Xtest)\n",
        "\n",
        "mae_nofilter = mae(ytest, skpred)\n",
        "mse_nofilter = mse(ytest, skpred)\n",
        "\n",
        "print(f'Absolute Error of theta in Test Set: {mae_nofilter}')\n",
        "print(f'Mean-Squared Error of theta in Test Set: {mse_nofilter}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXPAVbNN7sEX",
        "outputId": "c23f385a-81d2-47f4-cc5f-3edd3a7d3a28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Absolute Error of theta in Test Set: 0.03087682133959644\n",
            "Mean-Squared Error of theta in Test Set: 0.001484612850322486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the Best Z-Score to filter by"
      ],
      "metadata": {
        "id": "LUiAst2EFrXt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterating"
      ],
      "metadata": {
        "id": "S7vv1lCyJMId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bestz = 9000\n",
        "# minmae = mae_nofilter\n",
        "# minmse = mse_nofilter\n",
        "minmae = 9000\n",
        "minmse = 9000\n",
        "z = 1.14\n",
        "\n",
        "while z < 4:\n",
        "    donk = DONK\n",
        "\n",
        "    donk = donk.assign(\n",
        "        Weight=donk[['Weight','WeightAlt']].mean(axis=1) # Turn weight into average if there were two measurements\n",
        "        )\n",
        "    donk = donk.drop(columns='WeightAlt')\n",
        "\n",
        "    categs = mksel(dtype_include=object)\n",
        "    nums = mksel(dtype_include=np.number)\n",
        "    # print(f\"Ordinal Columns   : {categs(donk)}\")\n",
        "    # print(f\"Numerical Columns : {nums(donk)}\")\n",
        "\n",
        "    categ_linear_proc = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "    num_linear_proc = MinMaxScaler()\n",
        "\n",
        "    xform = mkxform((categ_linear_proc, categs),\n",
        "                    (num_linear_proc, nums), \n",
        "                    remainder=\"passthrough\")\n",
        "\n",
        "    categ_linear_proc = OneHotEncoder(handle_unknown=\"ignore\")\n",
        "    num_linear_proc = MinMaxScaler()\n",
        "\n",
        "    donk = xform.fit_transform(donk)\n",
        "    donk = pd.DataFrame(donk, columns=xform.get_feature_names_out())\n",
        "    donk = donk.rename(columns=(lambda x: x.replace('minmaxscaler__','').replace('onehotencoder__','')))\n",
        "    # print(donk)\n",
        "\n",
        "    donk_filtered = donk[(np.abs(stats.zscore(donk)) < z).all(axis=1)] # get rid of donkeys who fall outside of 99% of measurements\n",
        "    # donk_filtered = donk\n",
        "    # print(donk_filtered)\n",
        "\n",
        "    X = list(donk_filtered.columns)\n",
        "    X.remove('Weight')\n",
        "    X = donk_filtered[X]\n",
        "    y = donk_filtered['Weight']\n",
        "\n",
        "    Xtr, Xtest, ytr, ytest = train_test_split(X, y, test_size=.2, random_state=6)\n",
        "\n",
        "\n",
        "    # print(len(Xtr))\n",
        "    # print(len(Xtest))\n",
        "    # print(Xtr,end='\\n=================\\n\\n')\n",
        "    # print(ytr,end='\\n=================\\n\\n')\n",
        "    # print(Xtest,end='\\n=================\\n\\n')\n",
        "    # print(ytest,end='\\n=================\\n\\n')\n",
        "\n",
        "    skmodel = LinearRegression().fit(Xtr,ytr)\n",
        "\n",
        "    def mae(output, pred): # Mean Absolute Error\n",
        "        return np.mean(abs(output-pred))\n",
        "\n",
        "    def mse(output, pred): # Mean Squared Error\n",
        "        return np.mean((output-pred)**2)\n",
        "\n",
        "    X = list(donk.columns)\n",
        "    X.remove('Weight')\n",
        "    X = donk[X]\n",
        "    y = donk['Weight']\n",
        "    Xtr, Xtest, ytr, ytest = train_test_split(X, y, test_size=.2, random_state=rand)\n",
        "\n",
        "    skpred = skmodel.predict(Xtest)\n",
        "\n",
        "    curmae = mae(ytest, skpred)\n",
        "    curmse = mse(ytest, skpred)\n",
        "    if np.mean([curmse, curmae]) < np.mean([minmae,minmse]):\n",
        "        bestz = z\n",
        "        minmae = curmae\n",
        "        minmse = curmse\n",
        "    z += .01"
      ],
      "metadata": {
        "id": "g6C1ivpjDmU9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Displaying"
      ],
      "metadata": {
        "id": "inPZzw48JPGz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Best z score to filter by: {bestz}')\n",
        "print(f'Absolute Error of theta in Test Set: {minmae} (compared to {mae_nofilter})')\n",
        "print(f'Mean-Squared Error of theta in Test Set: {minmse} (compared to {mse_nofilter})')\n",
        "\n",
        "filtered_mae_diff = minmae / mae_nofilter\n",
        "filtered_mse_diff = minmse / mse_nofilter\n",
        "\n",
        "if filtered_mae_diff > 1 :\n",
        "    print(f'mae is {round((filtered_mae_diff-1)*100,2)}% worse')\n",
        "elif filtered_mae_diff < 1 :\n",
        "    print(f'mae is {round((1-filtered_mae_diff)*100,2)}% better')\n",
        "else:\n",
        "    print('No difference in mae values')\n",
        "\n",
        "if filtered_mse_diff > 1 :\n",
        "    print(f'mse is {round((filtered_mse_diff-1)*100,2)}% worse')\n",
        "elif filtered_mse_diff < 1 :\n",
        "    print(f'mse is {round((1-filtered_mse_diff)*100,2)}% better')\n",
        "else:\n",
        "    print('No difference in mse values')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLOqIAe-I1bz",
        "outputId": "2cfd6233-d380-4888-f07a-36150aa27c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best z score to filter by: 3.5999999999999663\n",
            "Absolute Error of theta in Test Set: 0.02997430753205772 (compared to 0.03087682133959644)\n",
            "Mean-Squared Error of theta in Test Set: 0.0014099519621956736 (compared to 0.001484612850322486)\n",
            "mae is 2.92% better\n",
            "mse is 5.03% better\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5 : Present Conclusions"
      ],
      "metadata": {
        "id": "7nNV0-EUa487"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "uhh"
      ],
      "metadata": {
        "id": "9WdE2EoBbr8W"
      }
    }
  ]
}